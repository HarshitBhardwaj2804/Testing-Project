{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4641e566",
   "metadata": {},
   "source": [
    "steps to implement:\n",
    "1. simple qa chat bot implement karna h.\n",
    "2. Then ek chatbot implement karna h jo user k first message ko around conversation ko name dega.\n",
    "3. Chat ka name print karwana h aur ans bhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a57147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "816a38db",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "624a9a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatmodel = ChatGroq(model=\"gemma2-9b-it\", groq_api_key=groq_api_key)\n",
    "namemodel = ChatGroq(model=\"gemma2-9b-it\", groq_api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cc0bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_instruction = \"\"\"\n",
    "You are an assistant, whose task is the analyse the first message of the user \n",
    "and generate a name for the convesation. Just write the name only that you have generated nothing else.  \n",
    "\"\"\"\n",
    "name_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", name_instruction),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d29978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "You are an intelligent assistant, your task is to answer the user querries as best as you can.\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", instruction),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dd75430",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8795e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|chatmodel|parser\n",
    "name_chain = name_prompt|namemodel|parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d92e7359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convestion Name : Let's Chat! \n",
      "\n",
      "\n",
      "I understand! I'm ready to answer your questions and do my best to be helpful. Ask me anything!  \n",
      "\n",
      "I can help with things like:\n",
      "\n",
      "* **Providing information:** I have access to a vast store of knowledge and can answer questions on a variety of topics.\n",
      "* **Generating creative content:** I can write stories, poems, articles, and even code.\n",
      "* **Summarizing text:** Need to get the gist of a long article? I can do that for you.\n",
      "* **Translating languages:** I can translate text between many different languages.\n",
      "\n",
      "Let me know how I can assist you! ðŸ˜Š  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "querry = input(\"Enter your question\")\n",
    "name = name_chain.invoke({\"input\":querry})\n",
    "print(\"Convestion Name :\", name)\n",
    "response = chain.invoke({\"input\":querry})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bd07cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Let's Chat!\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "679bc269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I understand! I'm ready to answer your questions and do my best to be helpful. Ask me anything!  \\n\\nI can help with things like:\\n\\n* **Providing information:** I have access to a vast store of knowledge and can answer questions on a variety of topics.\\n* **Generating creative content:** I can write stories, poems, articles, and even code.\\n* **Summarizing text:** Need to get the gist of a long article? I can do that for you.\\n* **Translating languages:** I can translate text between many different languages.\\n\\nLet me know how I can assist you! ðŸ˜Š\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "709002e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'foo': InMemoryChatMessageHistory(messages=[HumanMessage(content='What does cosine mean?', additional_kwargs={}, response_metadata={}), AIMessage(content='I\\'m happy to explain cosine!\\n\\n**Cosine (cos)** is a trigonometric function that relates an angle of a right triangle to the ratio of two of its sides. \\n\\nHere\\'s the breakdown:\\n\\n* **Right Triangle:**  We\\'re talking about a triangle with one angle measuring 90 degrees.\\n\\n* **Adjacent and Hypotenuse:**\\n    * **Adjacent** side: The side next to the angle you\\'re considering (but not the hypotenuse).\\n    * **Hypotenuse:** The longest side of the triangle, opposite the right angle.\\n\\n* **The Formula:**  \\n   cos(angle) = Adjacent side / Hypotenuse\\n\\n**In simpler words:** Cosine tells you how \"stretched out\" or \"compressed\" the adjacent side is compared to the hypotenuse of a right triangle, based on the angle.\\n\\n**Let me know if you\\'d like to see a visual example or have any other math questions!**\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 207, 'prompt_tokens': 25, 'total_tokens': 232, 'completion_time': 0.376363636, 'prompt_time': 0.001413989, 'queue_time': 0.255026442, 'total_time': 0.377777625}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--2bf216e0-3929-4383-8c0b-cc1a4900b018-0', usage_metadata={'input_tokens': 25, 'output_tokens': 207, 'total_tokens': 232})])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You're an assistant who's good at {ability}\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "hist_chain = prompt|chatmodel\n",
    "# Function to get seesion chats\n",
    "store = {}\n",
    "def get_session_history(sessionID:str)->BaseChatMessageHistory:\n",
    "    if sessionID not in store:\n",
    "        store[sessionID] = ChatMessageHistory()\n",
    "    return store[sessionID]\n",
    "\n",
    "message_hist_chain = RunnableWithMessageHistory(\n",
    "    hist_chain,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "ans = message_hist_chain.invoke(\n",
    "    {\"ability\": \"math\", \"question\": \"What does cosine mean?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"foo\"}}\n",
    "    )\n",
    "\n",
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a487872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'That\\'s a great question! It gets to the heart of why we have different trigonometric functions. \\n\\nWe use the ratio of the base (adjacent side) to the hypotenuse for cosine specifically because it highlights a particular relationship in the triangle. \\n\\nHere\\'s why it\\'s a useful ratio:\\n\\n* **Angle Relationship:** The cosine of an angle directly relates to how much the adjacent side is \"stretched\" or \"compressed\" compared to the hypotenuse. As the angle changes, the ratio of the base to the hypotenuse changes accordingly.\\n\\n* **Solving for Unknown Sides:** If you know the angle and the hypotenuse of a right triangle, you can use cosine to find the length of the adjacent side.\\n\\n* **Geometric Applications:** Cosine is fundamental in many geometric applications, such as:\\n    * **Finding distances:**  In surveying or navigation, cosine can help calculate distances based on angles and known lengths.\\n    * **Understanding forces:** In physics, cosine is used to analyze the components of forces acting at an angle.\\n    * **Modeling periodic phenomena:** Cosine functions are crucial in representing wave-like patterns in physics and engineering.\\n\\n\\nLet me know if you\\'d like to explore any of these applications further!\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = message_hist_chain.invoke(\n",
    "    {\"ability\": \"math\", \"question\": \"Why we always take the ratio of base and hypotenuse of the right angled triangle\"},\n",
    "    config={\"configurable\": {\"session_id\": \"foo\"}}\n",
    "    )\n",
    "ans.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bab0f3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What does cosine mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I\\'m happy to explain cosine!\\n\\n**Cosine (cos)** is a trigonometric function that relates an angle of a right triangle to the ratio of two of its sides. \\n\\nHere\\'s the breakdown:\\n\\n* **Right Triangle:**  We\\'re talking about a triangle with one angle measuring 90 degrees.\\n\\n* **Adjacent and Hypotenuse:**\\n    * **Adjacent** side: The side next to the angle you\\'re considering (but not the hypotenuse).\\n    * **Hypotenuse:** The longest side of the triangle, opposite the right angle.\\n\\n* **The Formula:**  \\n   cos(angle) = Adjacent side / Hypotenuse\\n\\n**In simpler words:** Cosine tells you how \"stretched out\" or \"compressed\" the adjacent side is compared to the hypotenuse of a right triangle, based on the angle.\\n\\n**Let me know if you\\'d like to see a visual example or have any other math questions!**\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 207, 'prompt_tokens': 25, 'total_tokens': 232, 'completion_time': 0.376363636, 'prompt_time': 0.001413989, 'queue_time': 0.255026442, 'total_time': 0.377777625}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--2bf216e0-3929-4383-8c0b-cc1a4900b018-0', usage_metadata={'input_tokens': 25, 'output_tokens': 207, 'total_tokens': 232}),\n",
       " HumanMessage(content='Why we always take the ratio of base and hypotenuse of the right angled triangle', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='That\\'s a great question! It gets to the heart of why we have different trigonometric functions. \\n\\nWe use the ratio of the base (adjacent side) to the hypotenuse for cosine specifically because it highlights a particular relationship in the triangle. \\n\\nHere\\'s why it\\'s a useful ratio:\\n\\n* **Angle Relationship:** The cosine of an angle directly relates to how much the adjacent side is \"stretched\" or \"compressed\" compared to the hypotenuse. As the angle changes, the ratio of the base to the hypotenuse changes accordingly.\\n\\n* **Solving for Unknown Sides:** If you know the angle and the hypotenuse of a right triangle, you can use cosine to find the length of the adjacent side.\\n\\n* **Geometric Applications:** Cosine is fundamental in many geometric applications, such as:\\n    * **Finding distances:**  In surveying or navigation, cosine can help calculate distances based on angles and known lengths.\\n    * **Understanding forces:** In physics, cosine is used to analyze the components of forces acting at an angle.\\n    * **Modeling periodic phenomena:** Cosine functions are crucial in representing wave-like patterns in physics and engineering.\\n\\n\\nLet me know if you\\'d like to explore any of these applications further!\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 263, 'prompt_tokens': 257, 'total_tokens': 520, 'completion_time': 0.478181818, 'prompt_time': 0.006317377, 'queue_time': 0.26489351299999997, 'total_time': 0.484499195}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--da2364a8-ff8c-459f-9c31-6bf6733501c9-0', usage_metadata={'input_tokens': 257, 'output_tokens': 263, 'total_tokens': 520})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[\"foo\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41c432e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## General functions\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import AIMessage, HumanMessage, BaseMessage\n",
    "\n",
    "class JSONChatMessageHistory(BaseChatMessageHistory):\n",
    "    def __init__(self, session_id: str, file_path: str = \"../chat_sessions.json\"):\n",
    "        self.session_id = session_id\n",
    "        self.file_path = file_path\n",
    "        self.messages = self._load_messages()\n",
    "\n",
    "    def _load_messages(self) -> List[BaseMessage]:\n",
    "        if not os.path.exists(self.file_path):\n",
    "            return []\n",
    "        with open(self.file_path, \"r\") as f:\n",
    "            all_data = json.load(f)\n",
    "        session_data = all_data.get(self.session_id, [])\n",
    "        return [self._dict_to_message(m) for m in session_data]\n",
    "\n",
    "    def _save_messages(self):\n",
    "        if os.path.exists(self.file_path):\n",
    "            with open(self.file_path, \"r\") as f:\n",
    "                all_data = json.load(f)\n",
    "        else:\n",
    "            all_data = {}\n",
    "\n",
    "        all_data[self.session_id] = [self._message_to_dict(m) for m in self.messages]\n",
    "\n",
    "        with open(self.file_path, \"w\") as f:\n",
    "            json.dump(all_data, f, indent=2)\n",
    "\n",
    "    def add_message(self, message: BaseMessage) -> None:\n",
    "        self.messages.append(message)\n",
    "        self._save_messages()\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []\n",
    "        self._save_messages()\n",
    "\n",
    "    def _message_to_dict(self, message: BaseMessage):\n",
    "        return {\"type\": message.type, \"content\": message.content}\n",
    "\n",
    "    def _dict_to_message(self, data: dict) -> BaseMessage:\n",
    "        if data[\"type\"] == \"human\":\n",
    "            return HumanMessage(content=data[\"content\"])\n",
    "        elif data[\"type\"] == \"ai\":\n",
    "            return AIMessage(content=data[\"content\"])\n",
    "        else:\n",
    "            raise ValueError(\"Unknown message type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38a13ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're right to ask again! My previous explanation was a bit technical.  \n",
      "\n",
      "Imagine a right triangle, like the corner of a square. \n",
      "\n",
      "* **Cosine** is a way to measure how \"stretched out\" or \"squished\" the triangle is, depending on the angle you choose.\n",
      "\n",
      "Think of it like this:\n",
      "\n",
      "* **Angle:** Choose one of the angles in the triangle (except the 90-degree one).\n",
      "* **Adjacent Side:** Look at the side next to the angle you chose.\n",
      "* **Hypotenuse:** This is the longest side, always opposite the right angle.\n",
      "\n",
      "Cosine tells you the ratio of the adjacent side's length to the hypotenuse's length. \n",
      "\n",
      "*  A cosine of 1 means the triangle is very \"stretched out\" â€“ the adjacent side is almost as long as the hypotenuse.\n",
      "*  A cosine of 0 means the triangle is very \"squished\" â€“ the adjacent side is very short.\n",
      "\n",
      "\n",
      "Let me know if you'd like me to draw a picture or give you another example!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## General functions\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import AIMessage, HumanMessage, BaseMessage\n",
    "\n",
    "class JSONChatMessageHistory(BaseChatMessageHistory):\n",
    "    def __init__(self, session_id: str, file_path: str = \"../chat_sessions.json\"):\n",
    "        self.session_id = session_id\n",
    "        self.file_path = file_path\n",
    "        self.messages = self._load_messages()\n",
    "\n",
    "    def _load_messages(self) -> List[BaseMessage]:\n",
    "        if not os.path.exists(self.file_path):\n",
    "            return []\n",
    "        with open(self.file_path, \"r\") as f:\n",
    "            all_data = json.load(f)\n",
    "        session_data = all_data.get(self.session_id, [])\n",
    "        return [self._dict_to_message(m) for m in session_data]\n",
    "\n",
    "    def _save_messages(self):\n",
    "        if os.path.exists(self.file_path):\n",
    "            with open(self.file_path, \"r\") as f:\n",
    "                all_data = json.load(f)\n",
    "        else:\n",
    "            all_data = {}\n",
    "\n",
    "        all_data[self.session_id] = [self._message_to_dict(m) for m in self.messages]\n",
    "\n",
    "        with open(self.file_path, \"w\") as f:\n",
    "            json.dump(all_data, f, indent=2)\n",
    "\n",
    "    def add_message(self, message: BaseMessage) -> None:\n",
    "        self.messages.append(message)\n",
    "        self._save_messages()\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []\n",
    "        self._save_messages()\n",
    "\n",
    "    def _message_to_dict(self, message: BaseMessage):\n",
    "        return {\"type\": message.type, \"content\": message.content}\n",
    "\n",
    "    def _dict_to_message(self, data: dict) -> BaseMessage:\n",
    "        if data[\"type\"] == \"human\":\n",
    "            return HumanMessage(content=data[\"content\"])\n",
    "        elif data[\"type\"] == \"ai\":\n",
    "            return AIMessage(content=data[\"content\"])\n",
    "        else:\n",
    "            raise ValueError(\"Unknown message type\")\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Set up the prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You're a helpful assistant skilled in {ability}.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# Set up the model\n",
    "llm = ChatGroq(model=\"gemma2-9b-it\")  # or llama3-8b-8192\n",
    "\n",
    "# Combine into a chain\n",
    "chain = prompt | llm\n",
    "\n",
    "# History setup\n",
    "def get_session_history(session_id: str):\n",
    "    return JSONChatMessageHistory(session_id=session_id, file_path=\"../chat_sessions.json\")\n",
    "\n",
    "# Wrap chain with memory\n",
    "message_chain = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "response = message_chain.invoke(\n",
    "    {\"ability\": \"math\", \"question\": \"What is cosine?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"math_test\"}}\n",
    ")\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "711eb4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = message_chain.invoke(\n",
    "    {\"ability\": \"Expert in handling people\", \"question\": \"I had applied for a job role a week later draft a mail asking about the hr is there is any update for my application\"},\n",
    "    config={\"configurable\": {\"session_id\": \"people-handler\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d223a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Subject: Following Up on Application for [Job Title] - [Your Name]\\n\\nDear [Hiring Manager name],\\n\\nI hope this email finds you well.\\n\\nI'm writing to follow up on my application for the [Job Title] position that I submitted last week on [Date you submitted application]. I'm very interested in this opportunity and believe my skills and experience in [mention 1-2 relevant skills] would be a great fit for your team.\\n\\nI understand that you're likely reviewing many applications, but I wanted to check in and see if there are any updates on the hiring timeline.\\n\\nThank you for your time and consideration.\\n\\nSincerely,\\n\\n[Your Name] \\n\\n\\n\\n**Key Points:**\\n\\n* **Reference the application date:** This helps the hiring manager quickly identify your application.\\n* **Keep it concise:** Hiring managers appreciate brevity.\\n* **Express continued interest:** Reiterate your enthusiasm for the role.\\n* **Be respectful of their time:** Acknowledge the volume of applications they likely receive.\\n\\n\\n\\nLet me know if you need help tailoring this further!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 226, 'prompt_tokens': 342, 'total_tokens': 568, 'completion_time': 0.410909091, 'prompt_time': 0.007072657, 'queue_time': 0.25655004400000003, 'total_time': 0.417981748}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--323708ec-013c-4847-9266-430d0c0495ea-0', usage_metadata={'input_tokens': 342, 'output_tokens': 226, 'total_tokens': 568})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4460ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def generate_session_id():\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S%f\")\n",
    "    date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    return [f\"session_{timestamp}\", date, time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43b689c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "details = generate_session_id()\n",
    "details1 = generate_session_id()\n",
    "details2 = generate_session_id()\n",
    "details3 = generate_session_id()\n",
    "details4 = generate_session_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60fdc84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('session_20250802093733652192',\n",
       " 'session_20250802093733652192',\n",
       " 'session_20250802093733652192',\n",
       " 'session_20250802093733652192',\n",
       " 'session_20250802093733652192')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details[0], details1[0], details2[0], details3[0], details4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c732a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, string\n",
    "def generate_session_details():\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S%f\")\n",
    "    rand_suffix = \"\".join(random.choices(string.ascii_lowercase + string.digits, k=6))\n",
    "    session_id = f\"session_{timestamp}-{rand_suffix}\"\n",
    "    date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    return [session_id, date, time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a0114fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "details = generate_session_id()\n",
    "details1 = generate_session_id()\n",
    "details2 = generate_session_id()\n",
    "details3 = generate_session_id()\n",
    "details4 = generate_session_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67d6cad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('session_20250802094353287473-61k2ia',\n",
       " 'session_20250802094353287473-jms6gr',\n",
       " 'session_20250802094353287473-3cq1on',\n",
       " 'session_20250802094353287473-rxg1q3',\n",
       " 'session_20250802094353288561-0zv8up')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details[0], details1[0], details2[0], details3[0], details4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4e462f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionid, date, time = generate_session_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fa90337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'session_20250802094535733990-iv1f76'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessionid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d3ba6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-08-02'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18a7d2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'09:45:35'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c4c5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
